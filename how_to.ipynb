{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the state evolution package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple example of how to use the state evolution package with custom teacher-student covariance rmrices. The class has three components:\n",
    "- `data_model`: this class defines everything concerning the generative model for data - i.e. it initialises the covariances $\\Psi, \\Phi, \\Omega$ and the teacher weights $\\theta_{0}$ and pre-computes all the quantities required for the state evolution.\n",
    "- `model`: this class defines the task. It basically contains the updates for the overlaps and their conjugates. So far, we have implemented ridge and logistic regression.\n",
    "- `algorithms`: this class defines the iterator for the state evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.models.logistic_regression import LogisticRegression # logistic regression task\n",
    "from state_evolution.algorithms.state_evolution import StateEvolution # Standard SP iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Custom data model: fixed sample complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a simple example where we input the covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.data_models.custom import Custom # Custom data model. You input the covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Gaussian covariate model is defined by a teacher-student model with:\n",
    "- Teacher : $y = f_{0}(\\theta_{0}\\cdot u)$, $\\theta_{0}\\sim\\mathcal{N}(0,\\rm{I}_{p})$\n",
    "- Student : $\\hat{y} = \\hat{f}(w\\cdot v)$\n",
    "where $z\\in\\mathbb{R}^{p}$ and $v\\in\\mathbb{R}^{d}$ are jointly Gaussian variables with covariances\n",
    "$$ \\Psi = \\mathbb{E}uu^{\\top}\\in\\mathbb{R}^{p\\times p}, \\qquad \\Phi = \\mathbb{E}uv^{\\top}\\in\\mathbb{R}^{p\\times d}, \\qquad \\Omega = \\mathbb{E}vv^{\\top}\\in\\mathbb{R}^{v\\times v}\n",
    "$$.\n",
    "\n",
    "The class `Custom` takes as input the three covariance matrices that define an instance of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's look at a simple model of a Gaussian teacher $\\theta_{0}\\sim\\mathcal{N}(0,\\rm{I}_{p})$ and both the teacher and student are Random Feature models on Gaussian i.i.d. data, with different dimensions and activation functions:\n",
    "$$\n",
    "u = \\rm{sign}\\left(\\frac{1}{\\sqrt{D}}\\bar{\\rm{F}}c\\right), \\qquad v = \\rm{erf}\\left(\\frac{1}{\\sqrt{D}}\\rm{F}c\\right), \\qquad c\\sim\\mathcal{N}(0,\\rm{I}_{D})\n",
    "$$\n",
    "\n",
    "In this case recall that the covariances can be computed analytically, and are given by:\n",
    "\n",
    " \\begin{align}\n",
    " \\Psi = \\bar{\\kappa}_{1}^2 \\bar{\\rm{F}}\\bar{\\rm{F}}^{\\top}+\\bar{\\kappa}_{\\star}^2\\rm{I}_{p}, && \\Phi = \\bar{\\kappa}_{1}\\kappa_{1} \\bar{\\rm{F}}\\rm{F}^{\\top}, && \\Omega = \\kappa_{1}^2 \\rm{F}\\rm{F}^{\\top}+\\kappa_{\\star}^2\\rm{I}_{d}\n",
    " \\end{align}\n",
    " \n",
    "with $\\kappa_{1} \\equiv \\mathbb{E}\\left[\\xi\\sigma(\\xi)\\right]$ and $\\kappa_{\\star}^2 \\equiv \\mathbb{E}\\left[\\sigma(\\xi)\\right]^2-\\kappa_{1}^2$ for $\\xi\\sim\\mathcal{N}(0,1)$ (idem for the bar). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "d     = 5000\n",
    "\n",
    "Psi   = np.identity(d)\n",
    "Omega = np.identity(d)\n",
    "Phi   = np.identity(d)\n",
    "\n",
    "# Teacher weights\n",
    "theta = np.random.normal(0,1, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our covariances, we can create our instance of `Custom`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = Custom(teacher_teacher_cov = Psi, \n",
    "                    student_student_cov = Omega, \n",
    "                    teacher_student_cov = Phi,\n",
    "                    teacher_weights = theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to load our task. Let's look at logistic regression. The `model` class takes as an input the sample complexity $\\alpha = n/d$ and the $\\ell_2$ regularisation $\\lambda>0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = LogisticRegression(sample_complexity = 0.5,\n",
    "                          regularisation= 0.01,\n",
    "                          data_model = data_model,\n",
    "                          Delta = 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is left is to initialise the saddle-point equation iterator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = StateEvolution(model = task,\n",
    "                    initialisation = 'uninformed',\n",
    "                    tolerance = 1e-7,\n",
    "                    damping = 0.5,\n",
    "                    verbose = True,\n",
    "                    max_steps = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply iterate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0, diff: 477.9685359426921, self overlaps: 0.04213746004115858, teacher-student overlap: 0.037294410668225426\n",
      "t: 1, diff: 239.9645188711907, self overlaps: 0.13122504413603597, teacher-student overlap: 0.07912260001153269\n",
      "t: 2, diff: 121.49947692184446, self overlaps: 0.3193662139208878, teacher-student overlap: 0.1326828515594862\n",
      "t: 3, diff: 62.76933907379919, self overlaps: 0.6528459050781013, teacher-student overlap: 0.19840437552959145\n",
      "t: 4, diff: 33.642240958693755, self overlaps: 1.1341923301045975, teacher-student overlap: 0.27092766919397904\n",
      "t: 5, diff: 18.97108187457425, self overlaps: 1.7172626683502519, teacher-student overlap: 0.34253423355424173\n",
      "t: 6, diff: 11.308440394084455, self overlaps: 2.3432454851880955, teacher-student overlap: 0.40734643805970083\n",
      "t: 7, diff: 7.098025954448542, self overlaps: 2.9680961468550118, teacher-student overlap: 0.46276839301564693\n",
      "t: 8, diff: 4.6546663898583205, self overlaps: 3.5652314189552903, teacher-student overlap: 0.5086112962761999\n",
      "t: 9, diff: 3.1613713961604635, self overlaps: 4.119334351528319, teacher-student overlap: 0.5458352927473098\n",
      "t: 10, diff: 2.205447994242845, self overlaps: 4.621543792431291, teacher-student overlap: 0.5757424253410197\n",
      "t: 11, diff: 1.568667564217105, self overlaps: 5.067184169705959, teacher-student overlap: 0.5996040634425669\n",
      "t: 12, diff: 1.130361719531618, self overlaps: 5.454809972859682, teacher-student overlap: 0.6185327149898434\n",
      "t: 13, diff: 0.8208754414732772, self overlaps: 5.785635658061894, teacher-student overlap: 0.6334618204283077\n",
      "t: 14, diff: 0.5982573273345012, self overlaps: 6.0629718169012925, teacher-student overlap: 0.6451632991513925\n",
      "t: 15, diff: 0.43614305793767105, self overlaps: 6.291606115118139, teacher-student overlap: 0.6542730189521018\n",
      "t: 16, diff: 0.31725557329775933, self overlaps: 6.4771858695492845, teacher-student overlap: 0.6613139532761567\n",
      "t: 17, diff: 0.22982259718048437, self overlaps: 6.6256741103082035, teacher-student overlap: 0.6667150284537242\n",
      "t: 18, diff: 0.16554894387977714, self overlaps: 6.742923873826727, teacher-student overlap: 0.6708262698408521\n",
      "t: 19, diff: 0.11843422481468768, self overlaps: 6.834383613636376, teacher-student overlap: 0.673931297736655\n",
      "t: 20, diff: 0.08405727233724458, self overlaps: 6.904922651668397, teacher-student overlap: 0.6762579745066594\n",
      "t: 21, diff: 0.059124073898308316, self overlaps: 6.958753961815983, teacher-student overlap: 0.6779876598796221\n",
      "t: 22, diff: 0.04273074704535429, self overlaps: 6.99942736139107, teacher-student overlap: 0.6792633186357195\n",
      "t: 23, diff: 0.03441104563386754, self overlaps: 7.029868422740282, teacher-student overlap: 0.6801965547339215\n",
      "t: 24, diff: 0.027252952775410844, self overlaps: 7.052443429615988, teacher-student overlap: 0.6808736724377629\n",
      "t: 25, diff: 0.021279686179524915, self overlaps: 7.069035499333632, teacher-student overlap: 0.6813607874649915\n",
      "t: 26, diff: 0.016410473538268633, self overlaps: 7.081122123590923, teacher-student overlap: 0.6817081029014894\n",
      "t: 27, diff: 0.012515124543641343, self overlaps: 7.089847942520382, teacher-student overlap: 0.6819534088563892\n",
      "t: 28, diff: 0.009447198170976057, self overlaps: 7.0960895841514295, teacher-student overlap: 0.682124903397731\n",
      "t: 29, diff: 0.007063257484309693, self overlaps: 7.100511420965143, teacher-student overlap: 0.6822434541563211\n",
      "t: 30, diff: 0.005232720582775241, self overlaps: 7.103611999641908, teacher-student overlap: 0.6823243782437488\n",
      "t: 31, diff: 0.0038421365503648053, self overlaps: 7.105761924790805, teacher-student overlap: 0.6823788188318205\n",
      "t: 32, diff: 0.002796238612402968, self overlaps: 7.107234231877716, teacher-student overlap: 0.6824148145760061\n",
      "t: 33, diff: 0.0020169676452467256, self overlaps: 7.108228268138841, teacher-student overlap: 0.6824381176381925\n",
      "t: 34, diff: 0.0014415669533888176, self overlaps: 7.108888280857919, teacher-student overlap: 0.6824527986457807\n",
      "t: 35, diff: 0.0010204325530878133, self overlaps: 7.1093176884211475, teacher-student overlap: 0.6824617128140142\n",
      "t: 36, diff: 0.0007149276454639919, self overlaps: 7.1095899516457415, teacher-student overlap: 0.6824668402568509\n",
      "t: 37, diff: 0.000495321936464066, self overlaps: 7.1097567472378636, teacher-student overlap: 0.6824695395875601\n",
      "t: 38, diff: 0.0003388989607168158, self overlaps: 7.109853995121217, teacher-student overlap: 0.6824707266788814\n",
      "t: 39, diff: 0.0002285559556578498, self overlaps: 7.109906362516341, teacher-student overlap: 0.6824710111803096\n",
      "t: 40, diff: 0.0001520326598638544, self overlaps: 7.109930621531151, teacher-student overlap: 0.6824707912501637\n",
      "t: 41, diff: 9.942271087570731e-05, self overlaps: 7.109937916109489, teacher-student overlap: 0.6824703172534978\n",
      "t: 42, diff: 6.818619616444366e-05, self overlaps: 7.10993556188726, teacher-student overlap: 0.682469746125079\n",
      "t: 43, diff: 5.391550716415949e-05, self overlaps: 7.109928234780112, teacher-student overlap: 0.6824691670882272\n",
      "t: 44, diff: 4.2046762807501636e-05, self overlaps: 7.109918824698255, teacher-student overlap: 0.682468629558038\n",
      "t: 45, diff: 3.241338084336576e-05, self overlaps: 7.1099090018046445, teacher-student overlap: 0.6824681539447124\n",
      "t: 46, diff: 2.468914785347387e-05, self overlaps: 7.109899766248578, teacher-student overlap: 0.6824677510794501\n",
      "t: 47, diff: 1.8637102730423294e-05, self overlaps: 7.109891544907474, teacher-student overlap: 0.6824674179869943\n",
      "t: 48, diff: 1.3925213196763764e-05, self overlaps: 7.109884530317284, teacher-student overlap: 0.6824671499198116\n",
      "t: 49, diff: 1.0317280681682028e-05, self overlaps: 7.109878696584895, teacher-student overlap: 0.6824669357768999\n",
      "t: 50, diff: 7.57459712341646e-06, self overlaps: 7.109873962523061, teacher-student overlap: 0.6824667686318842\n",
      "t: 51, diff: 5.514167988662777e-06, self overlaps: 7.109870174580214, teacher-student overlap: 0.6824666384100395\n",
      "t: 52, diff: 3.9784490688532514e-06, self overlaps: 7.109867199765571, teacher-student overlap: 0.6824665394965275\n",
      "t: 53, diff: 2.8531280519272784e-06, self overlaps: 7.109864871770788, teacher-student overlap: 0.6824664626565434\n",
      "t: 54, diff: 2.0045724423711775e-06, self overlaps: 7.109863107572405, teacher-student overlap: 0.6824664060905887\n",
      "t: 55, diff: 1.3966003032939156e-06, self overlaps: 7.109861778422815, teacher-student overlap: 0.6824663645802066\n",
      "t: 56, diff: 1.0757026019936333e-06, self overlaps: 7.109860790429503, teacher-student overlap: 0.6824663347776982\n",
      "t: 57, diff: 9.121645185850014e-07, self overlaps: 7.109860018571672, teacher-student overlap: 0.6824663105524769\n",
      "t: 58, diff: 7.049292882754798e-07, self overlaps: 7.109859454286073, teacher-student overlap: 0.6824662937470922\n",
      "t: 59, diff: 5.127788770264985e-07, self overlaps: 7.10985906605751, teacher-student overlap: 0.6824662831254883\n",
      "t: 60, diff: 4.124925353510278e-07, self overlaps: 7.10985877259541, teacher-student overlap: 0.6824662742903227\n",
      "t: 61, diff: 3.0311162624307997e-07, self overlaps: 7.109858567080126, teacher-student overlap: 0.6824662687348513\n",
      "t: 62, diff: 2.0507876541397962e-07, self overlaps: 7.109858431282884, teacher-student overlap: 0.682466266507061\n",
      "t: 63, diff: 1.6914921985300424e-07, self overlaps: 7.1098583257825645, teacher-student overlap: 0.6824662638544816\n",
      "t: 64, diff: 1.57359630992282e-07, self overlaps: 7.109858233735664, teacher-student overlap: 0.6824662604504944\n",
      "t: 65, diff: 7.527650969230137e-08, self overlaps: 7.109858193007423, teacher-student overlap: 0.6824662600817607\n",
      "Saddle point equations converged with t=66 iterations\n",
      "Elapsed time : 9.535422086715698\n"
     ]
    }
   ],
   "source": [
    "debut = time()\n",
    "sp.iterate()\n",
    "print(f'Elapsed time : {time() - debut}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, now you can check the result with method `get_info`, which gives everything you might be interested in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyperparameters': {'initialisation': 'uninformed',\n",
       "  'damping': 0.5,\n",
       "  'max_steps': 1000,\n",
       "  'tolerance': 1e-07}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Custom data model: whole learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is boring to repeat all the pipeline above every time you want to compute a new $\\alpha$. Instead, we can encapsulate it in an `experiment` class which allows one to compute a whole learning curve in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.experiments.learning_curve import CustomExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `CustomExperiment` takes as argument the task you want (from those implemented), the regularisation and the data_model, apart from all the hyperparameters of the iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment = CustomExperiment(task = 'logistic_regression', \n",
    "                                 regularisation = 1.0, \n",
    "                                 data_model = data_model, \n",
    "                                 initialisation='uninformed', \n",
    "                                 tolerance = 1e-7, \n",
    "                                 damping = 0.5, \n",
    "                                 verbose = True, \n",
    "                                 max_steps = 1000,\n",
    "                                 sigma = 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the learning curve, you need to pass a python iterable with the values of the sample complexity you want to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runninig sample complexity: 3.0\n",
      "Runninig sample complexity: 3.6315789473684212\n",
      "Runninig sample complexity: 4.2631578947368425\n",
      "Runninig sample complexity: 4.894736842105263\n",
      "Runninig sample complexity: 5.526315789473684\n",
      "Runninig sample complexity: 6.157894736842105\n",
      "Runninig sample complexity: 6.789473684210526\n",
      "Runninig sample complexity: 7.421052631578947\n",
      "Runninig sample complexity: 8.052631578947368\n",
      "Runninig sample complexity: 8.68421052631579\n",
      "Runninig sample complexity: 9.31578947368421\n",
      "Runninig sample complexity: 9.94736842105263\n",
      "Runninig sample complexity: 10.578947368421051\n",
      "Runninig sample complexity: 11.210526315789473\n",
      "Runninig sample complexity: 11.842105263157894\n",
      "Runninig sample complexity: 12.473684210526315\n",
      "Runninig sample complexity: 13.105263157894736\n",
      "Runninig sample complexity: 13.736842105263158\n",
      "Runninig sample complexity: 14.368421052631579\n",
      "Runninig sample complexity: 15.0\n"
     ]
    }
   ],
   "source": [
    "my_experiment.learning_curve(alphas = np.linspace(3.0, 15.0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.get_curve()` returns the learning curve as a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>gamma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>rho</th>\n",
       "      <th>sample_complexity</th>\n",
       "      <th>V</th>\n",
       "      <th>m</th>\n",
       "      <th>q</th>\n",
       "      <th>test_error</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.623050</td>\n",
       "      <td>0.294930</td>\n",
       "      <td>0.299415</td>\n",
       "      <td>0.422639</td>\n",
       "      <td>0.553901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>3.631579</td>\n",
       "      <td>0.576005</td>\n",
       "      <td>0.333504</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.417054</td>\n",
       "      <td>0.559249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>0.535351</td>\n",
       "      <td>0.367145</td>\n",
       "      <td>0.363274</td>\n",
       "      <td>0.412324</td>\n",
       "      <td>0.563884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>4.894737</td>\n",
       "      <td>0.499901</td>\n",
       "      <td>0.396708</td>\n",
       "      <td>0.388267</td>\n",
       "      <td>0.408253</td>\n",
       "      <td>0.567932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>5.526316</td>\n",
       "      <td>0.468738</td>\n",
       "      <td>0.422866</td>\n",
       "      <td>0.409824</td>\n",
       "      <td>0.404706</td>\n",
       "      <td>0.571492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>6.157895</td>\n",
       "      <td>0.441147</td>\n",
       "      <td>0.446158</td>\n",
       "      <td>0.428577</td>\n",
       "      <td>0.401583</td>\n",
       "      <td>0.574644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>6.789474</td>\n",
       "      <td>0.416556</td>\n",
       "      <td>0.467018</td>\n",
       "      <td>0.445020</td>\n",
       "      <td>0.398810</td>\n",
       "      <td>0.577452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>7.421053</td>\n",
       "      <td>0.394512</td>\n",
       "      <td>0.485797</td>\n",
       "      <td>0.459540</td>\n",
       "      <td>0.396330</td>\n",
       "      <td>0.579967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>8.052632</td>\n",
       "      <td>0.374643</td>\n",
       "      <td>0.502786</td>\n",
       "      <td>0.472445</td>\n",
       "      <td>0.394098</td>\n",
       "      <td>0.582231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>8.684211</td>\n",
       "      <td>0.356648</td>\n",
       "      <td>0.518223</td>\n",
       "      <td>0.483983</td>\n",
       "      <td>0.392078</td>\n",
       "      <td>0.584280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>9.315789</td>\n",
       "      <td>0.340277</td>\n",
       "      <td>0.532308</td>\n",
       "      <td>0.494354</td>\n",
       "      <td>0.390241</td>\n",
       "      <td>0.586142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>9.947368</td>\n",
       "      <td>0.325322</td>\n",
       "      <td>0.545208</td>\n",
       "      <td>0.503722</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.587841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>10.578947</td>\n",
       "      <td>0.311610</td>\n",
       "      <td>0.557063</td>\n",
       "      <td>0.512223</td>\n",
       "      <td>0.387024</td>\n",
       "      <td>0.589397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>11.210526</td>\n",
       "      <td>0.298994</td>\n",
       "      <td>0.567994</td>\n",
       "      <td>0.519970</td>\n",
       "      <td>0.385607</td>\n",
       "      <td>0.590827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>11.842105</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.578103</td>\n",
       "      <td>0.527055</td>\n",
       "      <td>0.384298</td>\n",
       "      <td>0.592146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>12.473684</td>\n",
       "      <td>0.276565</td>\n",
       "      <td>0.587479</td>\n",
       "      <td>0.533560</td>\n",
       "      <td>0.383086</td>\n",
       "      <td>0.593365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>13.105263</td>\n",
       "      <td>0.266555</td>\n",
       "      <td>0.596197</td>\n",
       "      <td>0.539550</td>\n",
       "      <td>0.381960</td>\n",
       "      <td>0.594496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>13.736842</td>\n",
       "      <td>0.257238</td>\n",
       "      <td>0.604323</td>\n",
       "      <td>0.545085</td>\n",
       "      <td>0.380911</td>\n",
       "      <td>0.595548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>14.368421</td>\n",
       "      <td>0.248544</td>\n",
       "      <td>0.611916</td>\n",
       "      <td>0.550213</td>\n",
       "      <td>0.379931</td>\n",
       "      <td>0.596528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016355</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.240414</td>\n",
       "      <td>0.619025</td>\n",
       "      <td>0.554976</td>\n",
       "      <td>0.379014</td>\n",
       "      <td>0.597444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   task  gamma  lambda       rho  sample_complexity         V  \\\n",
       "0   logistic_regression    1.0     1.0  1.016355           3.000000  0.623050   \n",
       "1   logistic_regression    1.0     1.0  1.016355           3.631579  0.576005   \n",
       "2   logistic_regression    1.0     1.0  1.016355           4.263158  0.535351   \n",
       "3   logistic_regression    1.0     1.0  1.016355           4.894737  0.499901   \n",
       "4   logistic_regression    1.0     1.0  1.016355           5.526316  0.468738   \n",
       "5   logistic_regression    1.0     1.0  1.016355           6.157895  0.441147   \n",
       "6   logistic_regression    1.0     1.0  1.016355           6.789474  0.416556   \n",
       "7   logistic_regression    1.0     1.0  1.016355           7.421053  0.394512   \n",
       "8   logistic_regression    1.0     1.0  1.016355           8.052632  0.374643   \n",
       "9   logistic_regression    1.0     1.0  1.016355           8.684211  0.356648   \n",
       "10  logistic_regression    1.0     1.0  1.016355           9.315789  0.340277   \n",
       "11  logistic_regression    1.0     1.0  1.016355           9.947368  0.325322   \n",
       "12  logistic_regression    1.0     1.0  1.016355          10.578947  0.311610   \n",
       "13  logistic_regression    1.0     1.0  1.016355          11.210526  0.298994   \n",
       "14  logistic_regression    1.0     1.0  1.016355          11.842105  0.287348   \n",
       "15  logistic_regression    1.0     1.0  1.016355          12.473684  0.276565   \n",
       "16  logistic_regression    1.0     1.0  1.016355          13.105263  0.266555   \n",
       "17  logistic_regression    1.0     1.0  1.016355          13.736842  0.257238   \n",
       "18  logistic_regression    1.0     1.0  1.016355          14.368421  0.248544   \n",
       "19  logistic_regression    1.0     1.0  1.016355          15.000000  0.240414   \n",
       "\n",
       "           m         q  test_error  train_loss  \n",
       "0   0.294930  0.299415    0.422639    0.553901  \n",
       "1   0.333504  0.334019    0.417054    0.559249  \n",
       "2   0.367145  0.363274    0.412324    0.563884  \n",
       "3   0.396708  0.388267    0.408253    0.567932  \n",
       "4   0.422866  0.409824    0.404706    0.571492  \n",
       "5   0.446158  0.428577    0.401583    0.574644  \n",
       "6   0.467018  0.445020    0.398810    0.577452  \n",
       "7   0.485797  0.459540    0.396330    0.579967  \n",
       "8   0.502786  0.472445    0.394098    0.582231  \n",
       "9   0.518223  0.483983    0.392078    0.584280  \n",
       "10  0.532308  0.494354    0.390241    0.586142  \n",
       "11  0.545208  0.503722    0.388563    0.587841  \n",
       "12  0.557063  0.512223    0.387024    0.589397  \n",
       "13  0.567994  0.519970    0.385607    0.590827  \n",
       "14  0.578103  0.527055    0.384298    0.592146  \n",
       "15  0.587479  0.533560    0.383086    0.593365  \n",
       "16  0.596197  0.539550    0.381960    0.594496  \n",
       "17  0.604323  0.545085    0.380911    0.595548  \n",
       "18  0.611916  0.550213    0.379931    0.596528  \n",
       "19  0.619025  0.554976    0.379014    0.597444  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_experiment.get_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note you can save it in a csv, you can just call the method `save_experiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_experiment.save_experiment(name='testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: defining a model directly as a function of the specta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though an instance of the Gaussian covariate model is defined by $(\\Psi, \\Phi, \\Omega, \\theta_{0})$, the saddle-point equations can be closed on the following scalar quantities:\n",
    "\\begin{align}\n",
    "\\rho = \\frac{1}{p}\\theta_{0}^{\\top}\\Psi\\theta_{0}, && \\omega_{i}\\in \\rm{spec}(\\Omega), && t_{i} = \\left(U^{\\top}\\Phi^{\\top}\\theta_{0}\\theta_{0}^{\\top}\\Phi U\\right)_{ii}, && i=1, \\cdots, d\n",
    "\\end{align}\n",
    "where $\\rm{spec}(\\Omega)$ are the eigenvalues of $\\Omega$ and $U\\in\\mathbb{R}^{d\\times d}$ are the eigenvectors of $\\Omega$. \n",
    "\n",
    "Therefore, we can also define our `data_model` by directly passing these quantities to the class `CustomSpectra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state_evolution.data_models.custom import CustomSpectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the spectrum\n",
      "Projection in student basis\n",
      "Computing rho\n"
     ]
    }
   ],
   "source": [
    "print('Computing the spectrum')\n",
    "spec_Omega, U = np.linalg.eigh(Omega)\n",
    "\n",
    "print('Projection in student basis')\n",
    "t = np.diagonal(U.T @ Phi.T @ theta.reshape(p, 1) @ theta.reshape(1, p) @ Phi @ U)\n",
    "\n",
    "print('Computing rho')\n",
    "rho = 1/p * theta.dot(Psi @ theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $\\rho\\in\\mathbb{R}$, but both $\\{\\omega_{i}\\}_{i=1}^{d}$ and $\\{t_{i}\\}_{i=1}^{d}$ are $d$-dimensional quantities. Therefore, we will also need to pass $\\gamma = p/d$ to our `data_model` in order to run the saddle-point equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model_spec = CustomSpectra(rho = rho, \n",
    "                                spec_Omega = spec_Omega, \n",
    "                                diagonal_term = t,\n",
    "                                gamma = p/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runninig sample complexity: 0.5\n"
     ]
    }
   ],
   "source": [
    "my_experiment = CustomExperiment(task = 'logistic_regression', \n",
    "                                 regularisation = 0.01, \n",
    "                                 data_model = data_model_spec, \n",
    "                                 initialisation='uninformed', \n",
    "                                 tolerance = 1e-7, \n",
    "                                 damping = 0.5, \n",
    "                                 verbose = True, \n",
    "                                 max_steps = 1000)\n",
    "\n",
    "my_experiment.learning_curve(alphas = [0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
